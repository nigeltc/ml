{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reuters Multiclass Classification\n",
    "From Deep Learning with Python, Chapter 3\n",
    "\n",
    "The Reuters dataset is a set of newswire stories and their topics published by Reuters in 1986. It consists of 8982 training stories and 2246 testing stories. There are 46 different topics which are unevenly distributed although each topic has at least 10 samples in the training set.\n",
    "\n",
    "_(How does this relate to the Reuters-21578 test set - [UCI Link](https://archive.ics.uci.edu/ml/datasets/reuters-21578+text+categorization+collection)?)_\n",
    "\n",
    "This is an example of a single-label, multiclass classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982 training samples\n",
      "2246 testing samples\n",
      "[1, 245, 273, 207, 156, 53, 74, 160, 26, 14, 46, 296, 26, 39, 74, 2979, 3554, 14, 46, 4689, 4329, 86, 61, 3499, 4795, 14, 61, 451, 4329, 17, 12]\n"
     ]
    }
   ],
   "source": [
    "print(\"{} training samples\".format(len(train_data)))\n",
    "print(\"{} testing samples\".format(len(test_data)))\n",
    "print(train_data[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data: 1 (8982,) object\n",
      "training labels: 1 (8982,) int64\n"
     ]
    }
   ],
   "source": [
    "print(\"training data:\", train_data.ndim, train_data.shape, train_data.dtype)\n",
    "print(\"training labels:\", train_labels.ndim, train_labels.shape, train_labels.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? ? ? said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "# Decoding newswires back to text\n",
    "word_index = reuters.get_word_index()\n",
    "reverse_word_index = dict([(value, key) for (key,value) in word_index.items()])\n",
    "decoded_newswire = [reverse_word_index.get(i-3, \"?\") for i in train_data[0]]\n",
    "print(\" \".join(decoded_newswire))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the Data\n",
    "As before, convert the sequences of integers into one-hot encoded vectors i.e. 10K vectors with the indexes corresponding to the integer value of the words set to 1.\n",
    "\n",
    "The labels are also one-hot encoded -- also known as categorical encoded. This could be done using vectorize_sequences() but Keras has a utility that does it automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data)\n",
    "x_test = vectorize_sequences(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: 2 (8982, 10000) float64\n",
      "y_train: 2 (8982, 46) float32\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train:\", x_train.ndim, x_train.shape, x_train.dtype)\n",
    "print(\"y_train:\", one_hot_train_labels.ndim, one_hot_train_labels.shape, one_hot_train_labels.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Model\n",
    "This is similar to the previous model but we increase the number of units in each hidden layer because there are 46 possible outputs. The last layer uses a \"softmax\" activation function which will cause it to output a probability distribution over the 46 possible output classes. The best loss function to usein this case is categorical_crossentropy which measures the distance between two probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validating Your Approach\n",
    "In order to monitor the accuracy of the model during training, we create a validation set by taking 1K samples from the original data. This allows us to check the model's accuracy against data that it has not been traing on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Your Model\n",
    "The call to ```model.fit()``` returns a ```History``` object which contains a ```history``` member which contains data about everything that happened during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/20\n",
      "7982/7982 [==============================] - 2s 255us/step - loss: 2.5322 - acc: 0.4955 - val_loss: 1.7208 - val_acc: 0.6120\n",
      "Epoch 2/20\n",
      "7982/7982 [==============================] - 1s 110us/step - loss: 1.4452 - acc: 0.6879 - val_loss: 1.3459 - val_acc: 0.7060\n",
      "Epoch 3/20\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 1.0953 - acc: 0.7650 - val_loss: 1.1714 - val_acc: 0.7430\n",
      "Epoch 4/20\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.8699 - acc: 0.8158 - val_loss: 1.0807 - val_acc: 0.7590\n",
      "Epoch 5/20\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.7036 - acc: 0.8475 - val_loss: 0.9846 - val_acc: 0.7820\n",
      "Epoch 6/20\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.5671 - acc: 0.8801 - val_loss: 0.9414 - val_acc: 0.8040\n",
      "Epoch 7/20\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.4586 - acc: 0.9050 - val_loss: 0.9091 - val_acc: 0.8020\n",
      "Epoch 8/20\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.3698 - acc: 0.9230 - val_loss: 0.9358 - val_acc: 0.7900\n",
      "Epoch 9/20\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.3034 - acc: 0.9307 - val_loss: 0.8910 - val_acc: 0.8090\n",
      "Epoch 10/20\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.2540 - acc: 0.9415 - val_loss: 0.9072 - val_acc: 0.8100\n",
      "Epoch 11/20\n",
      "7982/7982 [==============================] - 1s 114us/step - loss: 0.2188 - acc: 0.9469 - val_loss: 0.9167 - val_acc: 0.8130\n",
      "Epoch 12/20\n",
      "7982/7982 [==============================] - 1s 118us/step - loss: 0.1878 - acc: 0.9510 - val_loss: 0.9065 - val_acc: 0.8120\n",
      "Epoch 13/20\n",
      "7982/7982 [==============================] - 1s 117us/step - loss: 0.1704 - acc: 0.9523 - val_loss: 0.9357 - val_acc: 0.8090\n",
      "Epoch 14/20\n",
      "7982/7982 [==============================] - 1s 115us/step - loss: 0.1539 - acc: 0.9554 - val_loss: 0.9681 - val_acc: 0.8080\n",
      "Epoch 15/20\n",
      "7982/7982 [==============================] - 1s 119us/step - loss: 0.1391 - acc: 0.9558 - val_loss: 0.9687 - val_acc: 0.8140\n",
      "Epoch 16/20\n",
      "7982/7982 [==============================] - 1s 122us/step - loss: 0.1316 - acc: 0.9564 - val_loss: 1.0222 - val_acc: 0.8050\n",
      "Epoch 17/20\n",
      "7982/7982 [==============================] - 1s 124us/step - loss: 0.1221 - acc: 0.9577 - val_loss: 1.0318 - val_acc: 0.7940\n",
      "Epoch 18/20\n",
      "7982/7982 [==============================] - 1s 116us/step - loss: 0.1200 - acc: 0.9579 - val_loss: 1.0448 - val_acc: 0.8050\n",
      "Epoch 19/20\n",
      "7982/7982 [==============================] - 1s 116us/step - loss: 0.1139 - acc: 0.9595 - val_loss: 1.0993 - val_acc: 0.7980\n",
      "Epoch 20/20\n",
      "7982/7982 [==============================] - 1s 124us/step - loss: 0.1116 - acc: 0.9594 - val_loss: 1.0692 - val_acc: 0.8010\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=20,\n",
    "                   batch_size=512,\n",
    "                   validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Training and Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VNX9//HXBwxGZJPFIoIExYUt\nQIworvhTUXGr1qr8EPeitlZbqz+pVuvXiq3VKnWpit+qVRG0VVq1uFVt3SoaEBBECyJgBNksq6AE\nPr8/zs1kCDPJhORmJsn7+Xjcx8zce+6dT+5M7mfuOeeea+6OiIgIQLNsByAiIrlDSUFERBKUFERE\nJEFJQUREEpQUREQkQUlBREQSlBSkTphZczNbZ2Z71GXZbDKznmYWS5/tyts2s5fNbEQccZjZ9WZ2\n//auL02LkkITFR2Uy6ctZrYh6XXKg1NV3H2zu7dy90V1WTZXmdmrZnZDivnfM7MvzKxG/1vuPtTd\nx9dBXEeb2YJK2/6Vu19S222neK+LzOyfdb1dyS4lhSYqOii3cvdWwCLgpKR52xyczGyH+o8ypz0C\njEwxfyTwuLtvqd9wROqGkoKkZGY3m9mTZjbBzNYCZ5vZYDN718xWmdkSM7vLzPKi8juYmZtZQfT6\n8Wj5C2a21sz+bWY9alo2Wn68mf3HzFab2d1m9raZnZcm7kxivNjM5pnZf83srqR1m5vZnWa20sw+\nBY6rYhc9A3Q2s4OT1u8ADAMejV6fbGbTo79pkZldX8X+fqv8b6oujugX+pxou5+a2UXR/LbAc8Ae\nSWd9u0af5SNJ63/XzGZH++g1M9s3aVmpmV1pZh9G+3uCme1YxX5I9/d0NbPnzewrM5trZhckLTvI\nzKaZ2RozW2pmt0XzW5rZE9HfvcrM3jOzjjV9b6kdJQWpyqnAE0Bb4EmgDLgC6AgcQjhYXVzF+v8X\nuB5oTzgb+VVNy5rZrsBTwNXR+34GDKpiO5nEOAzYHxhISHZHR/MvBYYC/aP3OCPdm7j7euAvwDlJ\ns88CZrr77Oj1OuBswv47CbjCzE6sIvZy1cWxFDgBaAP8ALjbzArdfXX0PouSzvqWJa9oZr2Ax4Ef\nA52AfwDPlSfOyBnAMcCehP2U6oyoOk8SPqsuwJnAb83siGjZ3cBt7t4G6EnYjwDnAy2BrkAH4IfA\nxu14b6kFJQWpylvu/py7b3H3De7+vrtPcfcyd58PjAOOqGL9v7h7ibtvAsYDA7aj7InAdHf/W7Ts\nTmBFuo1kGOOv3X21uy8A/pn0XmcAd7p7qbuvBH5TRbwAfwLOSPolfU40rzyW19x9VrT/ZgATU8SS\nSpVxRJ/JfA9eA14FDstguxAS17NRbJuibbcBDkwqM9bdv4ze+3mq/ty2EZ3lDQJGu/tGd58GPExF\nctkE7G1mHdx9rbtPSZrfEegZtTuVuPu6mry31J6SglTl8+QXZrafmf3dzL40szXATYR/4nS+THr+\nNdBqO8p2SY7DwwiOpek2kmGMGb0XsLCKeAH+BawGTjKzfQhnHhOSYhlsZv80s+Vmthq4KEUsqVQZ\nh5mdaGZToqqZVYSzikyrWbokby9q+ygFdk8qU5PPLd17rIjOpsotTHqP84HewCdRFdGwaP4jhDOX\npyw01v/G1JZV75QUpCqVu0E+AMwi/JJrA9wAWMwxLCFUJwBgZsbWB7DKahPjEqBb0usqu8xGCeox\nwhnCSGCyuyefxUwEnga6uXtb4H8zjCVtHGa2E6G65dfAd9y9HfBy0nar67q6GOietL1mhP37RQZx\nZWox0NHMdk6at0f5e7j7J+5+FrAr8DvgaTPLd/dv3f1Gd+8FHEqovqxxTzipHSUFqYnWhF/G66O6\n6araE+rK80CRmZ0U/Wq8glAXHkeMTwE/MbPdo0bjazJY50+EdosLSKo6SorlK3ffaGYHEapuahvH\njkALYDmwOWqjOCpp+VLCAbl1Fds+2cyGRO0IVwNrgSlpylenmZnlJ0/u/hlQAtxiZjua2QDC2cF4\nADMbaWYdo7OU1YREtsXM/o+Z9Y0S1RpCddLm7YxLtpOSgtTEz4BzCQeRBwiNibFy96WEhso7gJXA\nXsAHwDcxxHgfoX7+Q+B9KhpAq4rvU+A9IB/4e6XFlwK/ttB761rCAblWcbj7KuCnwCTgK+B0QuIs\nXz6LcHayIOrBs2uleGcT9s99hMRyHHBy1L6wPQ4DNlSaIHxmexOqov4CXOvur0fLhgFzov1yO3Cm\nu39LqHZ6hpAQZhOqkhLVcVI/TDfZkYbEzJoTqidOd/c3sx2PSGOjMwXJeWZ2nJm1jXr5XE/odvpe\nlsMSaZSUFKQhOBSYT+iKehzwXXdPV30kIrWg6iMREUnQmYKIiCQ0uAtDOnbs6AUFBdkOQ0SkQZk6\ndeoKd6+qOzfQAJNCQUEBJSUl2Q5DRKRBMbPqrtAHVH0kIiJJlBRERCRBSUFERBIaXJuCiNSPTZs2\nUVpaysaNuqVBQ5Kfn0/Xrl3Jy8urvnAKSgoiklJpaSmtW7emoKCAMDit5Dp3Z+XKlZSWltKjR4/q\nV0ihSVQfjR8PBQXQrFl4HF/r26OLNH4bN26kQ4cOSggNiJnRoUOHWp3dNfozhfHjYdQo+Prr8Hrh\nwvAaYIRGahepkhJCw1Pbz6zRnylcd11FQij39ddhvoiIbC22pGBm3czsdTObY2azzeyKFGWGmNlq\nM5seTTfUdRyLFtVsvohk38qVKxkwYAADBgygc+fO7L777onX3377bUbbOP/88/nkk0+qLHPvvfcy\nvo7qkw899FCmT59eJ9vKpjirj8qAn7n7tOguUFPN7BV3/6hSuTfd/cS4gthjj1BllGq+iNSd8ePD\nGfiiReH/a8yY7a+i7dChQ+IAe+ONN9KqVSuuuuqqrcq4O+5Os2apf9s+/PDD1b7Pj370o+0LsBGL\n7UzB3Ze4+7To+VpgDlXfWzcWY8ZAy5Zbz2vZMswXkbpR3na3cCG4V7Td1XWnjnnz5tG3b18uueQS\nioqKWLJkCaNGjaK4uJg+ffpw0003JcqW/3IvKyujXbt2jB49mv79+zN48GCWLVsGwC9+8QvGjh2b\nKD969GgGDRrEvvvuyzvvvAPA+vXr+d73vkf//v0ZPnw4xcXFGZ8RbNiwgXPPPZd+/fpRVFTEG2+8\nAcCHH37IAQccwIABAygsLGT+/PmsXbuW448/nv79+9O3b1/+8pdqb/wXi3ppUzCzAmAgqe8DO9jM\nZpjZC2bWJ836o8ysxMxKli9fXqP3HjECxo2D7t3BLDyOG6dGZpG6VJ9tdx999BEXXnghH3zwAbvv\nvju/+c1vKCkpYcaMGbzyyit89FHlyghYvXo1RxxxBDNmzGDw4ME89NBDKbft7rz33nvcdtttiQRz\n991307lzZ2bMmMHo0aP54IMPMo71rrvuokWLFnz44Yc89thjjBw5km+//ZY//OEPXHXVVUyfPp33\n33+fLl26MHnyZAoKCpgxYwazZs3imGOO2b4dVEuxJwUza0W4Z+xP3H1NpcXTgO7u3h+4G/hrqm24\n+zh3L3b34k6dqh3kbxsjRsCCBbBlS3hUQhCpW/XZdrfXXntxwAEHJF5PmDCBoqIiioqKmDNnTsqk\nsNNOO3H88ccDsP/++7NgwYKU2z7ttNO2KfPWW29x1llnAdC/f3/69En52zWlt956i5EjRwLQp08f\nunTpwrx58zj44IO5+eab+e1vf8vnn39Ofn4+hYWFvPjii4wePZq3336btm3bZvw+dSnWpGBmeYSE\nMN7dn6m83N3XuPu66PlkIM/MOsYZk4jUvXRtdHG03e28886J53PnzuX3v/89r732GjNnzuS4445L\n2Ue/RYsWiefNmzenrKws5bZ33HHHbcrU5kZk6dYdOXIkkyZNYscdd+SYY47hjTfeoFevXpSUlNCn\nTx+uvvpqbrnllu1+39qIs/eRAX8E5rj7HWnKdI7KYWaDonhWxhWTiMQjW213a9asoXXr1rRp04Yl\nS5bw0ksv1fl7HHrooTz11FNAaAtIdSaSzuGHH57o3TRnzhyWLFlCz549mT9/Pj179uSKK67ghBNO\nYObMmXzxxRe0atWKkSNHcuWVVzJt2rQ6/1syEWfvo0OAkcCHZlbeKnMtsAeAu98PnA5camZlwAbg\nLNf9QUUanPIq2brqfZSpoqIievfuTd++fdlzzz055JBD6vw9fvzjH3POOedQWFhIUVERffv2TVu1\nc+yxxybGHDrssMN46KGHuPjii+nXrx95eXk8+uijtGjRgieeeIIJEyaQl5dHly5duPnmm3nnnXcY\nPXo0zZo1o0WLFtx///11/rdkosHdo7m4uNh1kx2R+M2ZM4devXplO4ysKysro6ysjPz8fObOncvQ\noUOZO3cuO+yQuwNCpPrszGyquxdXt27u/lUiIjlg3bp1HHXUUZSVleHuPPDAAzmdEGqr8f5lIiJ1\noF27dkydOjXbYdSbRj/2kYiIZE5JQUREEpQUREQkQUlBREQSlBREJOcMGTJkmwvRxo4dyw9/+MMq\n12vVqhUAixcv5vTTT0+77eq6tY8dO5avkwZzGjZsGKtWrcok9CrdeOON3H777bXeTpyUFEQk5wwf\nPpyJEyduNW/ixIkMHz48o/W7dOlSq1FGKyeFyZMn065du+3eXkOipCAiOef000/n+eef55tvvgFg\nwYIFLF68mEMPPTRx3UBRURH9+vXjb3/72zbrL1iwgL59+wJh+OqzzjqLwsJCzjzzTDZs2JAod+ml\nlyaG3f7lL38JhJFNFy9ezJFHHsmRRx4JQEFBAStWrADgjjvuoG/fvvTt2zcx7PaCBQvo1asXP/jB\nD+jTpw9Dhw7d6n2qk2qb69ev54QTTkgMpf3kk08CMHr0aHr37k1hYeE295ioC7pOQUSq9ZOfQF3f\nVGzAAIiOf9vo0KEDgwYN4sUXX+SUU05h4sSJnHnmmZgZ+fn5TJo0iTZt2rBixQoOOuggTj755LT3\nJr7vvvto2bIlM2fOZObMmRQVFSWWjRkzhvbt27N582aOOuooZs6cyeWXX84dd9zB66+/TseOW4/P\nOXXqVB5++GGmTJmCu3PggQdyxBFHsMsuuzB37lwmTJjAgw8+yBlnnMHTTz/N2WefXe1+SLfN+fPn\n06VLF/7+978DYfjvr776ikmTJvHxxx9jZnVSpVWZzhREJCclVyElVx25O9deey2FhYUcffTRfPHF\nFyxdujTtdt54443EwbmwsJDCwsLEsqeeeoqioiIGDhzI7Nmzqx3s7q233uLUU09l5513plWrVpx2\n2mm8+eabAPTo0YMBAwYAVQ/Pnek2+/Xrxz/+8Q+uueYa3nzzTdq2bUubNm3Iz8/noosu4plnnqFl\n5VEI64DOFESkWul+0cfpu9/9bmK00A0bNiR+4Y8fP57ly5czdepU8vLyKCgoSDlcdrJUZxGfffYZ\nt99+O++//z677LIL5513XrXbqWqsuPJhtyEMvZ1p9VG6be6zzz5MnTqVyZMn8/Of/5yhQ4dyww03\n8N577/Hqq68yceJE7rnnHl577bWM3idTOlMQkZzUqlUrhgwZwgUXXLBVA/Pq1avZddddycvL4/XX\nX2dhqpuwJ0kevnrWrFnMnDkTCMNu77zzzrRt25alS5fywgsvJNZp3bo1a9euTbmtv/71r3z99des\nX7+eSZMmcdhhh9Xq70y3zcWLF9OyZUvOPvtsrrrqKqZNm8a6detYvXo1w4YNY+zYsRnfFrQmdKYg\nIjlr+PDhnHbaaVv1RBoxYgQnnXQSxcXFDBgwgP3226/KbVx66aWcf/75FBYWMmDAAAYNGgSEu6gN\nHDiQPn36bDPs9qhRozj++OPZbbfdeP311xPzi4qKOO+88xLbuOiiixg4cGDGVUUAN998c6IxGaC0\ntDTlNl966SWuvvpqmjVrRl5eHvfddx9r167llFNOYePGjbg7d955Z8bvmykNnS0iKWno7IarNkNn\nq/pIREQSlBRERCRBSUFE0mpo1ctS+89MSUFEUsrPz2flypVKDA2Iu7Ny5Ury8/O3exvqfSQiKXXt\n2pXS0lKWL1+e7VCkBvLz8+natet2r6+kICIp5eXl0aNHj2yHIfVM1UciIpKgpCAiIglKCiIikqCk\nICIiCUoKIiKSoKQgIiIJSgoiIpKgpCAiIglKCiIikqCkICIiCUoKIiKSEFtSMLNuZva6mc0xs9lm\ndkWKMmZmd5nZPDObaWZFccUjIiLVi3NAvDLgZ+4+zcxaA1PN7BV3/yipzPHA3tF0IHBf9CgiIlkQ\n25mCuy9x92nR87XAHGD3SsVOAR714F2gnZntFldMIiJStXppUzCzAmAgMKXSot2Bz5Nel7Jt4sDM\nRplZiZmVaGx3EZH4xJ4UzKwV8DTwE3dfU3lxilW2uc2Tu49z92J3L+7UqVMcYYqICDEnBTPLIySE\n8e7+TIoipUC3pNddgcVxxiQiIunF2fvIgD8Cc9z9jjTFngXOiXohHQSsdvclccUkIiJVi7P30SHA\nSOBDM5sezbsW2APA3e8HJgPDgHnA18D5McYjIiLViC0puPtbpG4zSC7jwI/iikFERGpGVzSLiEiC\nkoKIiCQoKYiISIKSgoiIJCgpiIhIgpKCiIgkKCmIiEiCkoKIiCQoKYiISIKSgoiIJCgpiIhIgpKC\niIgkKCmIiEiCkoKIiCQoKYiISEKTSQplZfDcc9mOQkQktzWZpPDII3DyyfDqq9mOREQkdzWZpHD2\n2dCtG1x3HbhnOxoRkdzUZJJCfj788pcwZYqqkURE0mkySQHg3HNh773D2cKWLdmORkQk9zSppLDD\nDvCrX8GsWTBxYrajERHJPU0qKQB8//vQvz/ccANs2pTtaEREckuTSwrNmsGYMfDpp/Dww9mORkQk\ntzS5pAAwbBgcfDDcdBNs2JDtaEREckeTTApmcMst8MUXcN992Y5GRCR3NMmkAHDEETB0aEgOa9Zk\nOxoRkdzQZJMChLaFlSth7NhsRyIikhuadFIoLobTToPbbw/JQUSkqWvSSQHCdQvr1sGtt2Y7EhGR\n7GvySaF3bxg5Eu6+GxYvznY0IiLZ1eSTAsCNN8LmzXDzzdmOREQku2JLCmb2kJktM7NZaZYPMbPV\nZjY9mm6IK5bq9OgBP/gBPPggzJ+frShERLIvzjOFR4DjqinzprsPiKabYoylWtddF8ZGuvHGbEYh\nIpJdsSUFd38D+Cqu7de1Ll3gxz+Gxx+H2bOzHY2ISHZku01hsJnNMLMXzKxPlmPhmmugVSu4/vps\nRyIikh3ZTArTgO7u3h+4G/hruoJmNsrMSsysZPny5bEF1KEDXHUVTJoE778f29uIiOSsrCUFd1/j\n7uui55OBPDPrmKbsOHcvdvfiTp06xRrXT38KHTuGNoZy48dDQUEYYbWgILwWEWmMdsjWG5tZZ2Cp\nu7uZDSIkqKxfV9y6Nfz85/Czn8E//xkGzRs1Cr7+OixfuDC8BhgxImthiojEwjymu9ib2QRgCNAR\nWAr8EsgDcPf7zewy4FKgDNgAXOnu71S33eLiYi8pKYkl5nIbNoTbdnbvDqWlsGjRtmW6d4cFC2IN\nQ0SkzpjZVHcvrrZcXEkhLvWRFADGjYOLL06/3Ez3eRaRhiPTpJDt3kc56/zzYa+9IC8v9fI99qjf\neERE6kNGScHM9jKzHaPnQ8zscjNrF29o2ZWXF+7MtmkTtGix9bKWLcOw2yIijU2mZwpPA5vNrCfw\nR6AH8ERsUeWIs86Cfv2gfftwZmAW2hLGjVMjs4g0TpkmhS3uXgacCox1958Cu8UXVm5o1iwMkvfl\nl3DDDaENYcECJQQRabwyTQqbzGw4cC7wfDQvTW1743LSSXDggfA//wMbN2Y7GhGReGWaFM4HBgNj\n3P0zM+sBPB5fWLnDLNzH+fPP4YEHsh2NiEi8atwl1cx2Abq5+8x4QqpafXVJrezoo2HmTJg1C3bd\ntd7fXkSkVuq0S6qZ/dPM2phZe2AG8LCZ3VHbIBuSW2+FtWvhkEPg00+zHY2ISDwyrT5q6+5rgNOA\nh919f+Do+MLKPfvvD6+9Bl99BYMHa8A8EWmcMk0KO5jZbsAZVDQ0NzmDB8M778DOO8OQITB5crYj\nEhGpW5kmhZuAl4BP3f19M9sTmBtfWLlr333h3/8OjyefDA89lO2IRETqTkZJwd3/7O6F7n5p9Hq+\nu38v3tByV+fO8K9/wVFHwYUXwq9+BQ1sCCkRkZQybWjuamaTzGyZmS01s6fNrGvcweWy1q3huefg\nnHPChW0XXwxlZdmOSkSkdjKtPnoYeBboAuwOPBfNa9JatIBHHoFrr4UHH4RTT4X167MdlYjI9ss0\nKXRy94fdvSyaHgHivQVaA2EWBse79174+99DlVKMdwwVEYlVpklhhZmdbWbNo+lscuAuabnkhz+E\np5+GGTPCtQzz52c7IhGRmss0KVxA6I76JbAEOJ0w9IUkOfVUePVVWLkydF+dOjXbEYmI1EymvY8W\nufvJ7t7J3Xd19+8SLmSTSg4+GN5+G3baCY44Al58MdsRiYhkrjZ3XruyzqJoZPbbL1zLsPfecOKJ\noTFaRKQhqE1SsDqLohHabbdwLcORR4Zbe44Zo2sZRCT31SYp6BBXjTZtQo+ks8+GX/wCLrkE1q3L\ndlQiIulVmRTMbK2ZrUkxrSVcsyDVaNECHn0URo8Ot/HcY49wsduyZdmOTERkW1UmBXdv7e5tUkyt\n3X2H+gqyoTODX/86DKY3ZEi4xWf37qEbq4bhFpFcUpvqI6mhwYPhmWdgzpxQpfTHP8I++8CZZ6r7\nqojkBiWFLNh33zAsxoIFcPXVodtqcXG4Gvrll9UgLSLZo6RQD8aPh4ICaNYsPI4fH+bvthv85jfh\n/s+33QYffwzHHgsDB8ITT2iAPRGpf0oKMRs/HkaNgoULwxnAwoXhdXligNBL6aqr4LPP4OGH4dtv\nYcQI6NkT7r5bg+yJNGTu8OGHcNddoYbgjTdCR5NcrREwz9XI0iguLvaSkpJsh5GxgoKQCCrr3j1U\nH6WyZUvoyvrb38Jbb0H79nDZZWHqpGEIRXLeypXwyivw0kuhSnjx4m3LtGsXqpL33Tdc8Fr+vGdP\n2HHHuo/JzKa6e3G15ZQU4tWsWepfBGbh4F+dd94JyeFvfwtDZ1x8cWiH6KIOwSI5o6wMpkwJSeDF\nF6GkJPzf77ILHHNMqBY+5hjYvBk++SRUFX/yScX0xRcV22rWDHr02DZZ7Lcf7LprOHZsDyWFHLE9\nZwqpfPwx3HorPPYY7LADXHQRXHMNdOtWV5GKSE0sXBiSwEsvhYEwV68OB/QDDwxJ4Nhj4YADoHnz\n6re1di385z/bJoz//Ac2bKgod+WV8LvfbV+8Sgo5orxN4euvK+a1bBkuZBsxoubbmz8/NE6Xj6d0\n3nnw85+HXxYiEp916+DNNysSwccfh/ndulUkgaOOCmcHdWXLltARpTxJFBaGgTa3h5JCDhk/Hq67\nDhYtClc0jxmzfQkh2aJFoVrpwQfDKenIkeEOcHvvXTcxizQ27uHH2X//G6ZVqyqep5oqL9+4MWwn\nPz8cmMsTQa9e21+lU5+ynhTM7CHgRGCZu/dNsdyA3wPDgK+B89x9WnXbbYhJIU6LF4furPffH3ot\nDR8eElCvXtmOTKTuuIdfysuWhaqWdeu2fkw1L1WZ6rp5t20bfumnm/bfHw47LLTvNTS5kBQOB9YB\nj6ZJCsOAHxOSwoHA7939wOq2q6SQ2pdfhrrGP/wh1EF+//thEL5+/bIdmcj2WboU/vGP0Hvn5ZfD\ndzyd/Hxo1Qpat976sfK8qg76bdtmVv/fUGU9KURBFADPp0kKDwD/dPcJ0etPgCHuvqSqbSopVG3F\nCrjzznB9w9q14W5w118fLogTyWUbN4Yu2OVJYMaMML9Dh9Bz5+ijQ9tZ5QP9zjtDXl52Y28IMk0K\n2RzUbnfg86TXpdG8bZKCmY0CRgHsscce9RJcQ9WxY2iz+NnPwsUyY8fCpElwwgmhWumggxpG/ac0\nfu4we3ZFEvjXv0JiyMsL9zm/5RYYOjT8oGmmy2zrTTaTQqpDU8rTFncfB4yDcKYQZ1CNRfv2cOON\n8NOfwj33wB13hFuFdugQEkP5NGhQuKJapD4sW7Z1ldCS6Cdgr17hGpyhQ+Hww8NZgGRHNpNCKZDc\ny74rkOK6P6mNtm3DGcLll8Of/xzuH/3uu+GKaQhnDX36hBFcDzooPO67r36ZNXXu4YD90UcV08cf\nV/SZd996SjWv8vxvvoF588K8Dh1CddDQoaFqSNfb5I5stimcAFxGRUPzXe4+qLptqk2hbqxaBe+9\nFxLEv/8dHletCsvatg0X4JQnigMPrNu+15I73KG0NBz0Z8/eOgmsXl1Rrn378Gu+VauK6kezrafq\n5jVvHqqCVCWUHVlvaDazCcAQoCOwFPglkAfg7vdHXVLvAY4jdEk9392rPdorKcRjy5Zw9WRykpg1\nq2Iojv32CwmiXz/o3TtM3brVX/vEt9+G3ihdujTuHiJx2bw5XNsyZ862B//kW8R26hQ+2z59Kj7n\n3r1rN7yC5IasJ4W4KCnUn7Vr4f33KxLFe+9tfRvRVq3Cr8fkg0fv3hXDhNfU6tXhTnTl0/z5Fc8/\n/zwkqDZtQnI65JDQRnLggaEHioRf/StWhORePmRC+fN580L1TbnOnSs+r/IE0KuXBlxszJQUJBYr\nVoRfm8m/NGfPrmgwhHBhT7pksWzZ1gf+5IP/ypVbv1fHjrDXXhXTd74ThiB+++3wnu4h+RQWViSJ\nQw4JV43Xx6/aLVvCsObr1lVM5RdLVX6+bl0om58fElvr1mFK97x16/TdLNevh7lzKw74yQmgvAoQ\nwvp77RXu7lc+lX8u7dvHv38ktygpSL3673+3TRYffRR+4afTrFkYGHDPPbc++O+1V5hXVa+oVavC\nqJRvvx1Gkn333Yr7TnTpsnWSGDCg6n7s7mF7y5dvOy1bVvF8xYqtr56tyX0uWrQIyXLjxq1/sVcl\nP3/rhLHTTmF/lpZuXa5r19A5IPngv88+IQnvoDupS0RJoRGJY+yk+rJmTei18tFH4Yygc+eKA3/3\n7nV30VFZWTiLeOedikRRPjrGHIsTAAAMWUlEQVTtTjuFrrfFxbBp09YH+vKD/aZNqbfbunWoUunU\nKZy5tG277ZWylZ+net2iRcU2N20KiWXNmookk8nz9eth9923TgA9e4aLt0Sqo6TQSNT1KKtNyRdf\nhORQnig++CDsu113rTjQl0+p5nXqFH6tizQGSgqNRF3dj0FCNZF60EhTlWlSUE/hHLdoUc3mS3pK\nCCLVU1LIcemGetIQUCISByWFHDdmTKgHT9ayZZgvIlLXlBRy3IgRoVG5e/dQ/dG9uxqZRSQ+6sXc\nAIwYoSQgIvVDZwoiIpKgpCAiIglKCiIikqCkICIiCUoKIiKSoKQgIiIJSgpNwPjxFTe+KSgIr0VE\nUtF1Co1c5VFWFy4Mr0HXPojItnSm0Mhdd93Ww25DeH3dddmJR0Rym5JCI6dRVkWkJpQUGjmNsioi\nNaGk0MhplFURqQklhUZOo6yKSE2o91EToFFWRSRTOlMQEZEEJQUREUlQUhARkQQlBcmIhsoQaRrU\n0CzV0lAZIk2HzhSkWhoqQ6TpUFKQammoDJGmQ0lBqqWhMkSajliTgpkdZ2afmNk8MxudYvl5Zrbc\nzKZH00VxxiPbR0NliDQdsSUFM2sO3AscD/QGhptZ7xRFn3T3AdH0v3HFI9tPQ2WINB1x9j4aBMxz\n9/kAZjYROAX4KMb3lJhoqAyRpiHO6qPdgc+TXpdG8yr7npnNNLO/mFm3VBsys1FmVmJmJcuXL48j\nVhERId6kYCnmeaXXzwEF7l4I/AP4U6oNufs4dy929+JOnTrVcZhSH3Txm0jDEGdSKAWSf/l3BRYn\nF3D3le7+TfTyQWD/GOORLCm/+G3hQnCvuPhNiUEk98SZFN4H9jazHmbWAjgLeDa5gJntlvTyZGBO\njPFIlujiN5GGI7aGZncvM7PLgJeA5sBD7j7bzG4CStz9WeByMzsZKAO+As6LKx7JHl38JtJwmHvl\nav7cVlxc7CUlJdkOQ2qgoCBUGVXWvTssWFDf0Yg0TWY21d2LqyunK5oldrr4TaThUFKQ2OniN5GG\nQ0lB6sWIEaGqaMuW8FjThKAurSL1Q/dTkJyn+zmI1B+dKUjOU5dWkfqjpCA5T11aReqPkoLkPN3P\nQaT+KClIzquLLq1qqBbJjJKC5LzadmnV2EsimdMVzdLo6YpqEV3RLJKghmqRzCkpSKNXFw3VapOQ\npkJJQRq92jZUq01CmhIlBWn0attQrYvnpClRUpAmoTZjL9VFm4Sqn6ShUFIQqUZt2yRU/SQNiZKC\nSDVq2yah6idpSJQURKpR2zYJVT9JQ6KkIJKB2rRJ5EL1k5KKZEpJQSRm2a5+UlKRmlBSEIlZtquf\nciGpSMOhpCBSD7JZ/ZTtpAK1P9PQmUr9UVIQyXG1rX7KdlKp7ZlGLlR/Namk5O4Natp///1dpKl5\n/HH37t3dzcLj44/XbN2WLd3DITVMLVtmvo3u3bdet3zq3r1hrF/bv7+265dvY3s/v7pY390dKPEM\njrFZP8jXdFJSEKm5bCYVs9QHdbP6WV9JKcg0Keh+CiJSrfHjQxvCokWh2mnMmMzbRWp7P4vart+s\nWTiUVmYW2njiXj/bf3853U9BROpMbRrKa9smku02lWy3ydT3/UCUFEQkVrXtklvb9Zt6UqqxTOqY\ncmlSm4KI1FQ2G3rVphAztSmISENTmzaZulgfMm9TUFIQEWkC1NAsIiI1FmtSMLPjzOwTM5tnZqNT\nLN/RzJ6Mlk8xs4I44xERkarFlhTMrDlwL3A80BsYbma9KxW7EPivu/cE7gRujSseERGpXpxnCoOA\nee4+392/BSYCp1Qqcwrwp+j5X4CjzMxijElERKoQZ1LYHfg86XVpNC9lGXcvA1YDHSpvyMxGmVmJ\nmZUsX748pnBFRGSHGLed6hd/5a5OmZTB3ccB4wDMbLmZpbjoOyd0BFZkO4gq5Hp8kPsxKr7aUXy1\nU5v4umdSKM6kUAp0S3rdFVicpkypme0AtAW+qmqj7t6pLoOsS2ZWkkmXr2zJ9fgg92NUfLWj+Gqn\nPuKLs/rofWBvM+thZi2As4BnK5V5Fjg3en468Jo3tAsnREQakdjOFNy9zMwuA14CmgMPuftsM7uJ\ncLn1s8AfgcfMbB7hDOGsuOIREZHqxVl9hLtPBiZXmndD0vONwPfjjKGejct2ANXI9fgg92NUfLWj\n+Gon9vga3DAXIiISHw1zISIiCUoKIiKSoKRQQ2bWzcxeN7M5ZjbbzK5IUWaIma02s+nRdEOqbcUY\n4wIz+zB6722GlLXgrmjMqZlmVlSPse2btF+mm9kaM/tJpTL1vv/M7CEzW2Zms5LmtTezV8xsbvS4\nS5p1z43KzDWzc1OViSm+28zs4+gznGRm7dKsW+X3Icb4bjSzL5I+x2Fp1q1yjLQY43syKbYFZjY9\nzbqx7r90x5Ssff8yuemCpooJ2A0oip63Bv4D9K5UZgjwfBZjXAB0rGL5MOAFwsWDBwFTshRnc+BL\noHu29x9wOFAEzEqa91tgdPR8NHBrivXaA/Ojx12i57vUU3xDgR2i57emii+T70OM8d0IXJXBd+BT\nYE+gBTCj8v9TXPFVWv474IZs7L90x5Rsff90plBD7r7E3adFz9cCc9h2+I5cdwrwqAfvAu3MbLcs\nxHEU8Km7Z/0KdXd/g20vnEwem+tPwHdTrHos8Iq7f+Xu/wVeAY6rj/jc/WUPw8MAvEu4QDQr0uy/\nTGQyRlqtVRVfNN7aGcCEun7fTFRxTMnK909JoRaiob4HAlNSLB5sZjPM7AUz61OvgYWhQl42s6lm\nNirF8kzGpaoPZ5H+HzGb+6/cd9x9CYR/XGDXFGVyZV9eQDj7S6W670OcLouqtx5KU/2RC/vvMGCp\nu89Ns7ze9l+lY0pWvn9KCtvJzFoBTwM/cfc1lRZPI1SJ9AfuBv5az+Ed4u5FhGHLf2Rmh1dantGY\nU3GKrnI/GfhzisXZ3n81kQv78jqgDBifpkh134e43AfsBQwAlhCqaCrL+v4DhlP1WUK97L9qjilp\nV0sxr1b7T0lhO5hZHuHDG+/uz1Re7u5r3H1d9HwykGdmHesrPndfHD0uAyYRTtGTZTIuVdyOB6a5\n+9LKC7K9/5IsLa9Wix6XpSiT1X0ZNSyeCIzwqJK5sgy+D7Fw96XuvtndtwAPpnnfbO+/HYDTgCfT\nlamP/ZfmmJKV75+SQg1F9Y9/BOa4+x1pynSOymFmgwj7eWU9xbezmbUuf05ojJxVqdizwDlRL6SD\ngNXlp6n1KO2vs2zuv0qSx+Y6F/hbijIvAUPNbJeoemRoNC92ZnYccA1wsrt/naZMJt+HuOJLbqc6\nNc37ZjJGWpyOBj5299JUC+tj/1VxTMnO9y+uFvXGOgGHEk7PZgLTo2kYcAlwSVTmMmA2oSfFu8DB\n9RjfntH7zohiuC6anxyfEe6K9ynwIVBcz/uwJeEg3zZpXlb3HyFBLQE2EX59XUi4t8erwNzosX1U\nthj436R1LwDmRdP59RjfPEJ9cvn38P6obBdgclXfh3qK77Ho+zWTcIDbrXJ80ethhB43n9ZnfNH8\nR8q/d0ll63X/VXFMycr3T8NciIhIgqqPREQkQUlBREQSlBRERCRBSUFERBKUFEREJEFJQSRiZptt\n6xFc62zETjMrSB6hUyRXxXo7TpEGZoO7D8h2ECLZpDMFkWpE4+nfambvRVPPaH53M3s1GvDtVTPb\nI5r/HQv3N5gRTQdHm2puZg9GY+a/bGY7ReUvN7OPou1MzNKfKQIoKYgk26lS9dGZScvWuPsg4B5g\nbDTvHsIQ5IWEwejuiubfBfzLw4B+RYQrYQH2Bu519z7AKuB70fzRwMBoO5fE9ceJZEJXNItEzGyd\nu7dKMX8B8H/cfX40cNmX7t7BzFYQhm7YFM1f4u4dzWw50NXdv0naRgFh3Pu9o9fXAHnufrOZvQis\nI4wG+1ePBgMUyQadKYhkxtM8T1cmlW+Snm+mok3vBMJYVPsDU6ORO0WyQklBJDNnJj3+O3r+DmFU\nT4ARwFvR81eBSwHMrLmZtUm3UTNrBnRz99eB/we0A7Y5WxGpL/pFIlJhJ9v65u0vunt5t9QdzWwK\n4YfU8Gje5cBDZnY1sBw4P5p/BTDOzC4knBFcShihM5XmwONm1pYweu2d7r6qzv4ikRpSm4JINaI2\nhWJ3X5HtWETipuojERFJ0JmCiIgk6ExBREQSlBRERCRBSUFERBKUFEREJEFJQUREEv4/nxpgkEH4\nGAUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values)+1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Training and Validation Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VOXZ//HPFUAQQfZKZQu11gUk\nGFPcFYoiagUVVBBXqlSt0mr1KRVbffyVPtZa61oqtlqXAG4VqYIbtUVtq4IiCmhBDRg22UFAJHD9\n/rhPhkmYSSYkM5Pl+369zmvmrHPNycm55tz3fe5j7o6IiAhATrYDEBGR2kNJQUREYpQUREQkRklB\nRERilBRERCRGSUFERGKUFKQMM2tkZl+aWdeaXDabzOzbZpaWttflt21mL5vZiHTEYWa/MLM/7un6\nIqlQUqjjopNy6bDTzLbGjSc8OVXE3Xe4ewt3X1KTy9ZWZjbDzH6ZYPoQM1tqZlX6H3H3Ae5eWANx\nnWRmReW2/f/c/YrqbruSz3Qzuy5dnyG1n5JCHRedlFu4ewtgCXBG3LTdTk5m1jjzUdZqfwEuTDD9\nQuBxd9+Z2XCy6mJgbfSaUTouaw8lhXrOzH5lZk+Y2SQz2wRcYGZHm9l/zGy9mS03s3vMrEm0fOPo\n12JuNP54NH+6mW0ys3+bWfeqLhvNP9XM/mtmG8zsXjN708wuSRJ3KjH+0MwWmdk6M7snbt1GZvZ7\nM1tjZp8AAyvYRX8FOprZMXHrtwNOAx6NxgeZ2ZzoOy0xs19UsL/fKP1OlcVhZpeZ2YJou5+Y2WXR\n9FbA34CucVd934j+ln+JW/9MM5sX7aO/m9lBcfOKzew6M/sg2t+TzKxpBXG3AM4GrgQONbPe5eaf\nEP09NpjZ52Z2YTS9efQdl0TzZppZ00RXOlFMfaP3VTouo3UOM7NXzWytma0ws/8xs05mtsXMWsct\nd2Q0X4lmT7i7hnoyAEXASeWm/Qr4GjiD8CNgb+C7wJFAY+BbwH+Bq6PlGwMO5EbjjwOrgQKgCfAE\n4Rd0VZf9BrAJGBzNuw7YDlyS5LukEuNzQCsgl/AL96Ro/tXAPKAz0A6YGQ71pPvtYeCPceM/AmbF\njX8P6Bntv7zoO34/mvft+G0Db5R+p8riiP4m3wIs+oytQK9o3klAUYK/5V+i94cAX0brNQFujPZR\nk2h+MfAfoGP02f8FLqtgH1warZMDTAfujJvXPfrbnRvt+/ZA72jeA8AM4JtAI+C4KJ5E8RcDfffw\nuGwFrAR+DDQF9gX6RPNeBi6P+5x7gd9n+/+xrg5ZD0BDDf4xkyeFv1ey3vXAU9H7RCf6+BPmIODD\nPVh2JPB63DwDlpMkKaQY41Fx8/8KXB+9nxl/AiT86vcKtt2XkFSaRuNvAddUsPx9wG+j9xUlharG\n8Tzwo+h9ZUnhf4GJcfNygBXAcdF4MTAsbv6dwH0VfPY/gDui9xdGJ+DG0fgvSvd9uXUaAduAHgnm\npZIUqnJcXkhcoi633Ajgn3HHxhdAfk3/fzWUQcVHDcPn8SNmdrCZvRBdYm8EbiX8+ktmRdz7LUCL\nPVh2//g4PPwHFyfbSIoxpvRZwOIK4gX4J7ABOMPMvgMcDkyKi+VoM/uHma0ysw3AZQliSaTCOMzs\n+2b2VlQcsh4YkOJ2S7cd256Huo9ioFPcMin93aLivxOA0jqoZ6NlS4u7ugCfJFh1P2CvJPNSUZXj\nsguwKMl2ngXyLLSCGwiscvd39zCmBk9JoWEo3wzyAeBD4Nvuvi/wS8Iv93RaTihGAcDMjLInsPKq\nE+NywkmkVIVNZqME9RhwEeEX6TR3Xx23yGTgGaCLu7cC/pRiLEnjMLO9gaeB/wP2c/fWhGKQ0u1W\n1nR1GdAtbns5hP27NIW4yrso+tzpZraCcPLdK5oO4eR9QIL1VhKKgBLN2ww0j4uvMaEYK15Vjstk\nMeDuWwh/nxGEv99jiZaT1CgpNEwtCb+MN5vZIcAPM/CZzwP5ZnZGdIL4MdAhTTE+CfwkqoRsB/ws\nhXUeIfzKHBm9Lx/LWnf/ysyOAobVQBxNCSfeVcAOM/s+0D9u/kqgvZm1rGDbg8ysb1QZewOh3P+t\nFGOLdxHhBNw7bjgv2n4bQrHgQAvNdBubWXszy3P3HYTWW3eZWceoYv3YKJ6PgJZmdko0fjOhrqEi\nFf3NpxIq3q82s73MbF8z6xM3/1HC3+70KF7ZQ0oKDdNPCc0ONxF+nT2R7g9095WEE82dwBrCr773\nCGXSNR3jeELl5wfAO4Rf5JXF9wnwNtAMeKHc7CuB/4taydxIOCFXKw53Xw9cSyj6WAsMJSTO0vkf\nEn79FkWtcb5RLt55hP0znpBYBgKD3H17irEBYGbHEYqi7nf3FaVDFFcRcJ67f0aoEP5ZFOu7wGHR\nJq4FFgCzo3m/Bszd1wHXEBLs0mhefHFWIkn/5u6+ATgZGEKoM/gvcGLcujMJdRxvuXvSYkmpnEWV\nMyIZZWaNCEUgQ9399WzHI3Wfmc0EHnL3v2Q7lrpMVwqSMWY20MxaRe3lfwGUEH6di1RLVKzXE3gq\n27HUdUoKkknHAZ8S2vkPBM5092TFRyIpMbNC4EXgx+6+Odvx1HUqPhIRkRhdKYiISEyd6xukffv2\nnpubm+0wRETqlNmzZ69294qagQN1MCnk5uYya9asbIchIlKnmFlld/YDKj4SEZE4SgoiIhKjpCAi\nIjFKCiIiEqOkICIiMUoKIiJpVlgIubmQkxNeC3d7enp6168KJQURqfeyeVIuLIRRo2DxYnAPr6NG\npb6N6q5fZdl+9FtVhyOOOMJFJLMef9y9Wzd3s/D6+ON1Z/3HH3dv3tw9nFLD0Lx56tuo7vrdupVd\nt3To1i0z65ciyeNMyw9ZP8lXdVBSEKm6unxSresnZbPE65tlZv1SSgoi9Ug2T+rZPqnW9ZNytr9/\nqVSTguoURGq56pYpjx0LW7aUnbZlS5ieiiVLqja9tq3fNckTupNNr+n1x42D5s3LTmvePEzPxPpV\npaQgkmbVreTM9kk92yfVun5SHjECJkyAbt3ALLxOmBCmZ2L9KkvlcqI2DSo+krqkukU37tkvvsh2\nnUBN7MNsV5TXBqhOQaRmVOeEUBPlwdk+qZduo662PpJASUGkBlT3hFoTLUdqw0ld6r5Uk0Kdexxn\nQUGB63kKkim5uaFit7xu3aCoKP3rlyosDHUIS5aEsvRx49JYpiz1kpnNdveCypZTRbNIBapbSVtT\nLUdGjAhJZOfO8KqEIOmipCBSgeq2fMl4yxGRalJSkHqvOk1Ca+KXvn7lS12ipCD1WnVv/NIvfWlo\nVNEs9VpNVfSK1HWqaJZ6ozrFP9WtKBZpaJQUpFarbvFPdSuKRRoaJQWp1arb70+mOxMTqeuUFKRW\nq27xjyqKRaqmcbYDEKlI166JK4qrUvwzYoSSgEiqdKUgtZqKf0QyS0lBajUV/4hklpKCpF11HzKj\nO4JFMkd1CpJWpU1KS1sQlTYpBZ3cRWqjtF4pmNlAM/vYzBaZ2ZgE87uZ2Qwzm2tm/zCzzumMRzKv\nuk1KRSSz0pYUzKwRcD9wKnAoMNzMDi232B3Ao+7eC7gV+L90xSPZoTuKReqWdF4p9AEWufun7v41\nMBkYXG6ZQ4EZ0fvXEsyXOk53FIvULelMCp2Az+PGi6Np8d4HhkTvzwJamlm7NMYkGaYmpSJ1SzqT\ngiWYVr5L1uuBE83sPeBEYClQstuGzEaZ2Swzm7Vq1aqaj1TSRk1KReqWtHWdbWZHA7e4+ynR+M8B\n3D1hvYGZtQA+cvcKK5vVdbaISNXVhq6z3wEONLPuZrYXMAyYGr+AmbU3s9IYfg48lMZ4RESkEmlL\nCu5eAlwNvAQsAJ5093lmdquZDYoW6wt8bGb/BfYDVNIsIpJFevKaiEgDUBuKj6SeqG43FSJSd6ib\nC6mQuqkQaVh0pSAVUjcVIg2LkoJUSN1UiDQsSgpSIXVTIdKwKClIhdRNhUjDoqQgFVI3FSINi1of\nSaX04HuRhkNXCiIiEqOkICIiMUoKIiISo6QgIiIxSgoiIhKjpCAiIjFKCg2AejkVkVTpPoV6Tr2c\nikhV6EqhnlMvpyJSFUoK9Zx6ORWRqlBSqOfUy6mIVIWSQj2nXk5FpCqUFOo59XIqIlWh1kcNgHo5\nFZFU6UpBRERilBRERCRGSUFERGKUFEREJEZJQUREYpQU6gB1aCcimaImqbWcOrQTkUzSlUItpw7t\nRCSTdKVQy6lDu/qhpATWr4fGjaFpU9hrL2jUKNtRpd/mzfDRR2FYvBgOPRSOOw7at892ZJKMkkIt\n17Vr+GdKNF2ywx02bYJVq2D16jCUvk80bfVqWLdu9+00ahQSROmw115lx8tPa9YM2rULJ9QOHcq+\nlr5v2jTz+wPCd1ywYPch2Y+XQw+F448PwwknQJcumY1XklNSqOXGjStbpwDq0G5PrF8Pf/tbOJlv\n27Zr+PrrsuMVTd+6FdasCSfA7dsTf85ee5U9UR9xxK4TduvWsGNH1T93y5ayn792bUhMibRosXui\nKH1t1y4klvKJp6KkVDq9cWPYuRM+/zzxyX/Nml0x7L03HHxwuCI4+GA45JAwdOkCc+fCzJnw+usw\ncSI88EBYp1u3XQni+OPhoINCX12SeebJjq5aqqCgwGfNmpXtMDKqsDDUISxZEq4Qxo1TJXOqNmyA\nu++GO+8M78uryq/1Zs12P9mWP/G2aJH+k9mOHSExJLsySTStfL1UVeXkhKGkZNe0du12nfDjT/5d\nu4ZlU/ke8Uni9dfhiy/CvA4dQlIpTRJ5eSExyZ4zs9nuXlDpculMCmY2ELgbaAT8yd1vKze/K/AI\n0DpaZoy7T6tomw0xKdQG27fDrFnh5LjvvtCyZXht1qx2/qLbuBHuuSckg3Xr4MwzYcyY0KQ3/mTf\nEMr1ISSFNWvgq6+SX5FUNm3HjrD/Sk/+HTrUbIzusHBhSA6lieKzz8K8Fi3g2GNhwAD4/vfhO9+p\n2c+uyPLlMG1aiGn//UOC6t0bDjywbh0/WU8KZtYI+C9wMlAMvAMMd/f5cctMAN5z9/Fmdigwzd1z\nK9qukkLmvfIK/PjHoZigvEaNQnKITxSlr+WndegQ/qm/+c30xfrll3DvvXDHHeHX9BlnwC23QH5+\n+j5T0mfp0l1J4h//2HUMfvvbcNppcPrpcOKJNVuXsmMHvPMOvPBCSAbvvhumt28fiiFLr5b23hsO\nOywkiN69Q7Lo1SsksHRwD0MqV2GJpJoU0nlB1gdY5O6fRgFNBgYD8+OWcWDf6H0rYFka45Eq+vRT\n+OlPYcoUOOAAeOyxcILfuDEMmzaVfS19v25dqByPn1/KDI4+Gs46KwwHHFAzsW7eDPffD7/9bSgu\nOf30kAwKKv0XkNqsUycYNiwMAEVF4UT9wgvhuSD33AP77AMnnRT+5qedFtapqvXr4aWXwnanTw/H\nUE5OOFZ//euw7cMOC1fMCxbAnDlheP99eOqpEAuE4/uAA8omit69Q0zlr6hLSsLVW1UaLNx3H/zg\nB9XapZVK55XCUGCgu18WjV8IHOnuV8ct803gZaANsA9wkrvPTrCtUcAogK5dux6xOFFzHKkxmzfD\nbbeFE2zjxnDTTXDttXv+a2znzrDNoiJ47jn461/hvffCvLy8kBzOPht69qx6UdSWLTB+PPzmN+Gf\nZ+DAkAyOPHLPYpW6Y8sWeO21cCJ/4YVdLZ3y8sJJ/PTTw3GQqIjHHebP37Xum2+GK4S2beHUU0Ny\nOeWUUG9SGXcoLi6bKObMgU8+2bVM27bh+N6+veIWaaVatUpcZ3X22XDUUVXbT6VqQ/HROcAp5ZJC\nH3e/Jm6Z66IYfmdmRwN/Bnq6+85k21XxUfq4wxNPwA03hIP8ggtCctiTX16VKSqCZ58NCeLNN8Nn\nf/vbuxJEnz4VXyZv3Qp//GNIBitXwsknw//+b/hlJw1PspN8u3bhh0JpMdN77+0qFir9bZlKEtkT\nGzfCBx/sShTz5oUip0Qn+/hp7dqF+q6almpSwN3TMgBHAy/Fjf8c+Hm5ZeYBXeLGPwW+UdF2jzji\nCJea99577scfH0ot8/Pd33gjc5+9YoX7Aw+4n3KKe+PGIYb993e/6ir3V191//rrXctu3ep+993u\nHTuG5fr3z2ysUjesXes+ebL7hRe6t29fWhofhn32cR88OBxzn3+e7UgzB5jlKZy703ml0JhQ0dwf\nWEqoaD7f3efFLTMdeMLd/2JmhwAzgE5eQVC6UqhZa9bAL34R2ou3bRvKT0eOzF6rivXrwy+5v/41\nlO1u3Qpt2sCgQaHt+n33wbJl0LdvuDI44YTsxCl1x44doeXcG2+EeoGarpiuK7JefBQFcRpwF6G5\n6UPuPs7MbiVkrKlRi6MHgRaESuf/cfeXK9qmkkLNKCkJieAXvwiXuVdfDTffHE7AtcWWLfDyyyFB\n/O1vIWEcf3xIBv36ZTs6kbqlViSFdFBSqL5//ANGjw7lnf37h5u7evTIdlQV27493E3bvXvtvC9C\npLZLNSmol9QGZMkSOPfc8Ct70yZ45plwD0JtTwgATZrAt76lhCCSbkoKDcC2baFrjIMPhuefh1tv\nDS01zj5bJ1kRKUu9idRzM2bAj34EH38MQ4fC736nHlZFJDldKdRTK1bA+eeHOz1LSkJLnqeeUkIQ\nkYopKdQzO3aEZpsHHRTqDG6+OVQoDxyY7chEpC6oNCmY2dVmVosaKkoy77wT7gS+5ppwK/yHH4Yu\nH/beO9uRiUhdkcqVQkfgHTN70swGmqlqsqoKC0OXwzk54bWwsGa3v24dXHVVuEV/+fLQVcWLL4au\nfUVEqqLSpODuNwEHEvolugRYaGa/NrMa6t+yfissDE9OW7w43GS/eHEYr4nE4B56Lj344HAj2o9/\nHJ6Fe+65alUkInsmpTqFqNuJFdFQQujV9Gkzuz2NsdULY8fu/tSrLVvC9OqYPz/cb3DRRaH9/uzZ\n8Pvfh66tRUT2VCp1CqPNbDZwO/AmcJi7XwkcAQxJc3x1XrIHlyebXpnNm8MTxPLywqMMJ0wIPUL2\n7r3nMYqIlErlPoX2wNnuXuYhBu6+08y+n56w6o+uXXd10Vt+elVNnRq6p1i8GC69NHQbXdOPRBSR\nhi2V4qNpwNrSETNraWZHArh7ggc0Srxx46B587LTmjcP01OxbVuoN+jTBwYPDo+1fP11eOghJQQR\nqXmpJIXxwJdx45ujaZKCESNCEU+3bqHyt1u3MD5iRMXrLV0aejDt2jXUG2zaBH/4Q3he7HHHZSZ2\nEWl4Uik+svjnG0TFRuoeowpGjKg8CUBoTfTmm+HB83/9a7gR7Ywzwn0H/furRZGIpF8qJ/dPzWw0\nu64OriI8IU1qyNatMHFiuBN5zhxo3Rp+8pNw70H37tmOTkQaklSKj64AjiE8Pa0YOBIYlc6gGorF\ni+FnP4POneGyy8KVwYQJoejot79VQhCRzKv0SsHdvwCGZSCWBsEdXnstFBFNnRqKhM48MxQRnXCC\niohEJLsqTQpm1gz4AdADaFY63d1HpjGuemfbNnj44VBENG8etG8frhKuvBK6dMl2dCIiQSrFR48R\n+j86Bfgn0BnYlM6g6putW0OF8ZVXhgeGP/xweLTkr3+thCAitUsqFc3fdvdzzGywuz9iZhOBl9Id\nWH2xZUtICK+9Bn/6E4wcqSIiEam9UkkK26PX9WbWk9D/UW7aIqpHvvwyJISZM+GRR+DCC7MdkYhI\nxVJJChOi5yncBEwFWgC/SGtU9cCmTXDaafCvf4U7ks8/P9sRiYhUrsKkYGY5wEZ3XwfMBL6Vkajq\nuI0bw5PO3n4bJk0KXVmLiNQFFVY0u/tO4OoMxVIvrF8PAwaEp6A98YQSgojULam0PnrFzK43sy5m\n1rZ0SHtkddC6dXDyyaF/oqefhiHqWFxE6phU6hRK70f4Udw0R0VJZaxZExLCvHmh36Lvq1NxEamD\nUrmjWZ0tVGLVKjjpJPj4Y5gyBU49NdsRiYjsmVTuaL4o0XR3f7Tmw6l7vvgi9GC6aFHotmLAgGxH\nJCKy51IpPvpu3PtmQH/gXaDBJ4UVK0JC+OwzeP758F5EpC5LpfjomvhxM2tF6PqiQVu2DL73PSgu\nhmnToG/fbEckIlJ9e/KwnC3AgTUdSF1SXBwSwvLlMH06HH98tiMSEakZqdQp/I3Q2ghCE9ZDgSfT\nGVRttmQJ9OsXKpdfegmOOSbbEYmI1JxUrhTuiHtfAix29+I0xVOrFRWFhLB2LbzyChx5ZLYjEhGp\nWakkhSXAcnf/CsDM9jazXHcvSmtktcySJXDiiaELixkzoKAg2xGJiNS8VO5ofgrYGTe+I5pWKTMb\naGYfm9kiMxuTYP7vzWxONPzXzNanFnbm/epXochICUFE6rNUrhQau/vXpSPu/rWZ7VXZSmbWCLgf\nOJnwbOd3zGyqu8+P29a1cctfAxxeleAzZdMmmDgRhg+H/PxsRyMikj6pXCmsMrNBpSNmNhhYncJ6\nfYBF7v5plFQmA4MrWH44MCmF7WbcpEmweTOMGpXtSERE0iuVK4UrgEIzuy8aLwYS3uVcTifg87jx\nYiBh1ayZdQO6A39PMn8UMAqga9euKXx0zXrgAejVC/r0yfhHi4hkVCo3r30CHGVmLQBz91Sfz5zo\noZOeYBrAMOBpd9+RJIYJwASAgoKCZNtIi9mzQ6+n99+vx2iKSP1XafGRmf3azFq7+5fuvsnM2pjZ\nr1LYdjEQ/1j6zsCyJMsOo5YWHT3wADRtCrfdBjk5kJsLhYXZjkpEJD1SqVM41d1jrYKip7CdlsJ6\n7wAHmln3qGJ6GOFxnmWY2UFAG+DfqYWcOZs2waOPQkkJfP45uMPixaFuQYlBROqjVJJCIzNrWjpi\nZnsDTStYHgB3LyE8te0lYAHwpLvPM7Nb4yuuCRXMk909o8VCqZg4EbZtgx3lCrW2bIGxY7MTk4hI\nOqVS0fw4MMPMHo7GLwUeSWXj7j4NmFZu2i/Ljd+SyrayYcKE5POWLMlcHCIimZJKRfPtZjYXOIlQ\nefwi0C3dgWVbaQVz27ahW4vystAISkQk7VIpPgJYQbireQjheQoL0hZRLfHAA9C8eahgbt687Lzm\nzWHcuOzEJSKSTkmvFMzsO4TK4eHAGuAJQpPUfhmKLWtK72AeNgwuvzwkgbFjQ5FR164hIYwYke0o\nRURqXkXFRx8BrwNnuPsiADO7toLl642JE8vewTxihJKAiDQMFRUfDSEUG71mZg+aWX8S35BW70yY\noDuYRaRhSpoU3P1Zdz8POBj4B3AtsJ+ZjTezevt4+lmzQgXzD3+oO5hFpOGptKLZ3Te7e6G7f59w\nV/IcYLdusOuLCRNCHYKKi0SkIUq19REA7r7W3R9w9++lK6Bsiq9gbtUq29GIiGRelZJCfVe+gllE\npKFRUoijCmYRaeiUFCKqYBYRUVKIUQWziIiSAgAbN6qCWUQElBQAPYNZRKRUg08K7noGs4hIqQaf\nFGbPhvfeUwWziAgoKaiCWUQkToNOCqpgFhEpq0EnBVUwi4iU1WCTgiqYRUR212CTgiqYRUR212CT\nQukzmFXBLCKyS4NMChs3hvoEVTCLiJTVIJOCKphFRBJrcElBFcwiIsk1uKSgCmYRkeQaXFJQBbOI\nSHINKimogllEpGINKinoGcwiIhVrMElBFcwiIpVrMElh9myYM0cVzCIiFWkwSeHll1XBLCJSmQaT\nFG68ERYuVAWziEhF0poUzGygmX1sZovMbEySZc41s/lmNs/MJqYznv33T+fWRUTqvsbp2rCZNQLu\nB04GioF3zGyqu8+PW+ZA4OfAse6+zsy+ka54RESkcum8UugDLHL3T939a2AyMLjcMpcD97v7OgB3\n/yKN8YiISCXSmRQ6AZ/HjRdH0+J9B/iOmb1pZv8xs4GJNmRmo8xslpnNWrVqVZrCFRGRdCaFRA0/\nvdx4Y+BAoC8wHPiTmbXebSX3Ce5e4O4FHTp0qPFARUQkSGdSKAa6xI13BpYlWOY5d9/u7p8BHxOS\nhIiIZEE6k8I7wIFm1t3M9gKGAVPLLTMF6AdgZu0JxUmfpjEmERGpQNqSgruXAFcDLwELgCfdfZ6Z\n3Wpmg6LFXgLWmNl84DXgBndfk66YRESkYuZevpi/disoKPBZs2ZlOwwRkTrFzGa7e0FlyzWYO5pF\nRKRySgoiIhKjpCAiIjFKCiIiEqOkICIiMUoKIiISo6QgIiIxSgoiIhKjpCAiIjFKCiIiEqOkICIi\nMWl7HKeIpNf27dspLi7mq6++ynYoUos0a9aMzp0706RJkz1aX0lBpI4qLi6mZcuW5ObmYpbomVbS\n0Lg7a9asobi4mO7du+/RNlR8JFJHffXVV7Rr104JQWLMjHbt2lXr6lFJQaQOU0KQ8qp7TCgpiIhI\njJKCSANRWAi5uZCTE14LC/d8W2vWrKF379707t2bjh070qlTp9j4119/ndI2Lr30Uj7++OMKl7n/\n/vsprE6g5axcuZLGjRvz5z//uca2Wd/oyWsiddSCBQs45JBDUlq2sBBGjYItW3ZNa94cJkyAESOq\nF8ctt9xCixYtuP7668tMd3fcnZyc2vPb85577uGpp56iadOmvPrqq2n7nJKSEho3zl47nkTHhp68\nJiIxY8eWTQgQxseOrdnPWbRoET179uSKK64gPz+f5cuXM2rUKAoKCujRowe33nprbNnjjjuOOXPm\nUFJSQuvWrRkzZgx5eXkcffTRfPHFFwDcdNNN3HXXXbHlx4wZQ58+fTjooIP417/+BcDmzZsZMmQI\neXl5DB8+nIKCAubMmZMwvkmTJnHXXXfx6aefsmLFitj0F154gfz8fPLy8hgwYAAAmzZt4uKLL+aw\nww6jV69eTJkyJRZrqcmTJ3PZZZcBcMEFF/DTn/6Ufv36ceONN/Kf//yHo48+msMPP5xjjz2WhQsX\nAiFhXHvttfTs2ZNevXrxhz/8gZdeeolzzjkntt3p06dz7rnnVvvvsSfUJFWkAViypGrTq2P+/Pk8\n/PDD/PGPfwTgtttuo23btpSUlNCvXz+GDh3KoYceWmadDRs2cOKJJ3Lbbbdx3XXX8dBDDzFmzJjd\ntu3uvP3220ydOpVbb72VF19icIX2AAAR8ElEQVR8kXvvvZeOHTvyzDPP8P7775Ofn58wrqKiItat\nW8cRRxzB0KFDefLJJxk9ejQrVqzgyiuv5PXXX6dbt26sXbsWCFdAHTp04IMPPsDdWb9+faXf/ZNP\nPmHGjBnk5OSwYcMG3njjDRo1asSLL77ITTfdxBNPPMH48eNZtmwZ77//Po0aNWLt2rW0bt2a0aNH\ns2bNGtq1a8fDDz/MpZdeWtVdXyN0pSDSAHTtWrXp1XHAAQfw3e9+NzY+adIk8vPzyc/PZ8GCBcyf\nP3+3dfbee29OPfVUAI444giKiooSbvvss8/ebZk33niDYcOGAZCXl0ePHj0Srjtp0iTOO+88AIYN\nG8akSZMA+Pe//02/fv3o1q0bAG3btgXg1Vdf5Uc/+hEQWvS0adOm0u9+zjnnxIrL1q9fz9lnn03P\nnj25/vrrmTdvXmy7V1xxBY0aNYp9Xk5ODueffz4TJ05k7dq1zJ49O3bFkmm6UhBpAMaNS1ynMG5c\nzX/WPvvsE3u/cOFC7r77bt5++21at27NBRdckLAN/V577RV736hRI0pKShJuu2nTprstk2q96KRJ\nk1izZg2PPPIIAMuWLeOzzz7D3RM240w0PScnp8znlf8u8d997NixnHLKKVx11VUsWrSIgQMHJt0u\nwMiRIxkyZAgA5513XixpZJquFEQagBEjQqVyt25gFl5ropK5Mhs3bqRly5bsu+++LF++nJdeeqnG\nP+O4447jySefBOCDDz5IeCUyf/58duzYwdKlSykqKqKoqIgbbriByZMnc+yxx/L3v/+dxYsXA8SK\njwYMGMB9990HhBP5unXryMnJoU2bNixcuJCdO3fy7LPPJo1rw4YNdOrUCYC//OUvsekDBgxg/Pjx\n7Nixo8zndenShfbt23PbbbdxySWXVG+nVIOSgkgDMWIEFBXBzp3hNd0JASA/P59DDz2Unj17cvnl\nl3PsscfW+Gdcc801LF26lF69evG73/2Onj170qpVqzLLTJw4kbPOOqvMtCFDhjBx4kT2228/xo8f\nz+DBg8nLy2NEtGNuvvlmVq5cSc+ePenduzevv/46AL/5zW8YOHAg/fv3p3Pnzknj+tnPfsYNN9yw\n23f+4Q9/SMeOHenVqxd5eXmxhAZw/vnn0717d77zne9Ua59Uh5qkitRRVWmSWp+VlJRQUlJCs2bN\nWLhwIQMGDGDhwoVZbRK6p6644gqOPvpoLr744mptpzpNUuveXhMRifPll1/Sv39/SkpKcHceeOCB\nOpkQevfuTZs2bbjnnnuyGkfd23MiInFat27N7Nmzsx1GtSW7tyLTVKcgIiIxSgoiIhKjpCAiIjFK\nCiIiEqOkICJV1rdv391uRLvrrru46qqrKlyvRYsWQLibeOjQoUm3XVmz87vuuostcbdnn3baaSn1\nTZSq0s71GiIlBRGpsuHDhzN58uQy0yZPnpzyiXT//ffn6aef3uPPL58Upk2bVqb30upYsGABO3fu\nZObMmWzevLlGtplIsq48sk1JQaQe+MlPoG/fmh1+8pPknzd06FCef/55tm3bBoQeSJctW8Zxxx0X\nu28gPz+fww47jOeee2639YuKiujZsycAW7duZdiwYfTq1YvzzjuPrVu3xpa78sorY91u33zzzUB4\nJsKyZcvo168f/fr1AyA3N5fVq1cDcOedd9KzZ0969uwZ63a7qKiIQw45hMsvv5wePXowYMCAMp8T\nb+LEiVx44YUMGDCAqVOnxqYvWrSIk046iby8PPLz8/nkk08AuP322znssMPIy8uL9ewaf7WzevVq\ncnNzgdDdxTnnnMMZZ5zBgAEDKtxXjz76aOyu5wsvvJBNmzbRvXt3tm/fDoQuRHJzc2PjNSWt9ymY\n2UDgbqAR8Cd3v63c/EuA3wJLo0n3ufuf0hmTiFRfu3bt6NOnDy+++CKDBw9m8uTJnHfeeZgZzZo1\n49lnn2Xfffdl9erVHHXUUQwaNCjps4PHjx9P8+bNmTt3LnPnzi3T9fW4ceNo27YtO3bsoH///syd\nO5fRo0dz55138tprr9G+ffsy25o9ezYPP/wwb731Fu7OkUceyYknnhjrr2jSpEk8+OCDnHvuuTzz\nzDNccMEFu8XzxBNP8Morr/Dxxx9z3333xa5+RowYwZgxYzjrrLP46quv2LlzJ9OnT2fKlCm89dZb\nNG/ePNaPUUX+/e9/M3fu3Fh34on21fz58xk3bhxvvvkm7du3Z+3atbRs2ZK+ffvywgsvcOaZZzJ5\n8mSGDBlCkyZNqvKnq1TakoKZNQLuB04GioF3zGyqu5fvreoJd786XXGINATRD+KMKi1CKk0KDz30\nEBA6j7vxxhuZOXMmOTk5LF26lJUrV9KxY8eE25k5cyajR48GoFevXvTq1Ss278knn2TChAmUlJSw\nfPly5s+fX2Z+eW+88QZnnXVWrLfSs88+m9dff51BgwbRvXt3evfuDSTvnvudd96hQ4cOdOvWjc6d\nOzNy5EjWrVtH48aNWbp0aaz/pGbNmgGhG+xLL72U5s2bA7u63a7IySefHFsu2b76+9//ztChQ2NJ\nr3T5yy67jNtvv50zzzyThx9+mAcffLDSz6uqdBYf9QEWufun7v41MBkYnMbPS6omn00rIsGZZ57J\njBkzePfdd9m6dWvsF35hYSGrVq1i9uzZzJkzh/322y9hd9nxEl1FfPbZZ9xxxx3MmDGDuXPncvrp\np1e6nYr6civtdhuSd889adIkPvroI3JzcznggAPYuHEjzzzzTNLtJusGu3HjxuzcuROouHvtZPsq\n2XaPPfZYioqK+Oc//8mOHTtiRXA1KZ1JoRPwedx4cTStvCFmNtfMnjazLok2ZGajzGyWmc1atWpV\nlYIofTbt4sXgHl5HjVJiEKmuFi1a0LdvX0aOHFmmgnnDhg184xvfoEmTJrz22muxLqmTOeGEEyiM\n/iE//PBD5s6dC4Qy83322YdWrVqxcuVKpk+fHlunZcuWbNq0KeG2pkyZwpYtW9i8eTPPPvssxx9/\nfErfZ+fOnTz11FPMnTs31r32c889x6RJk9h3333p3LkzU6ZMAWDbtm1s2bKFAQMG8NBDD8UqvUuL\nj3Jzc2Ndb1RUoZ5sX/Xv358nn3ySNWvWlNkuwEUXXcTw4cPT9mS2dCaFRAWI5dPt34Bcd+8FvAo8\nkmhD7j7B3QvcvaBDhw5VCiJTz6YVaYiGDx/O+++/H3vyGYSy91mzZlFQUEBhYSEHH3xwhdu48sor\n+fLLL+nVqxe33347ffr0AUKz0MMPP5wePXowcuTIMl1Qjxo1ilNPPTVW0VwqPz+fSy65hD59+nDk\nkUdy2WWXcfjhh6f0XWbOnEmnTp1iz0CAkGTmz5/P8uXLeeyxx7jnnnvo1asXxxxzDCtWrGDgwIEM\nGjSIgoICevfuzR133AHA9ddfz/jx4znmmGNiFeCJJNtXPXr0YOzYsZx44onk5eVx3XXXlVln3bp1\naWsym7aus83saOAWdz8lGv85gLv/X5LlGwFr3b1Vovmlqtp1dk5OuELY/fNCv/IidZW6zm6Ynn76\naZ577jkee+yxpMvU1q6z3wEONLPuhNZFw4Dz4xcws2+6+/JodBCwoKaD6No1FBklmi4iUpdcc801\nTJ8+nWnTpqXtM9KWFNy9xMyuBl4iNEl9yN3nmdmtwCx3nwqMNrNBQAmwFrikpuPI5LNpRUTS6d57\n7037Z6T1PgV3nwZMKzftl3Hvfw78PJ0xlD5ycOxYWLIkXCGMG5eZRxGKpFuyVirScFW3SqBBPGRn\nxAglAal/mjVrxpo1a2jXrp0SgwAhIaxZsyZ2H8WeaBBJQaQ+6ty5M8XFxVS1mbbUb82aNaNz5857\nvL6Sgkgd1aRJE7p3757tMKSeUYd4IiISo6QgIiIxSgoiIhKTtjua08XMVgEVd6aSPe2B5Pe0Z5/i\nq57aHh/U/hgVX/VUJ75u7l5pP0F1LinUZmY2K5XbyLNF8VVPbY8Pan+Miq96MhGfio9ERCRGSUFE\nRGKUFGrWhGwHUAnFVz21PT6o/TEqvupJe3yqUxARkRhdKYiISIySgoiIxCgpVJGZdTGz18xsgZnN\nM7MfJ1imr5ltMLM50fDLRNtKY4xFZvZB9Nm7PabOgnvMbFH0fOz8DMZ2UNx+mWNmG83sJ+WWyfj+\nM7OHzOwLM/swblpbM3vFzBZGr22SrHtxtMxCM7s4Q7H91sw+iv5+z5pZ6yTrVngspDnGW8xsadzf\n8bQk6w40s4+j43FMBuN7Ii62IjObk2TdtO7DZOeUrB1/7q6hCgPwTSA/et8S+C9waLll+gLPZzHG\nIqB9BfNPA6YTnqN9FPBWluJsBKwg3FST1f0HnADkAx/GTbsdGBO9HwP8JsF6bYFPo9c20fs2GYht\nANA4ev+bRLGlciykOcZbgOtTOAY+Ab4F7AW8X/7/KV3xlZv/O+CX2diHyc4p2Tr+dKVQRe6+3N3f\njd5vIjxCtFPFa9U6g4FHPfgP0NrMvpmFOPoDn7h71u9Qd/eZhKf/xRsMPBK9fwQ4M8GqpwCvuPta\nd18HvAIMTHds7v6yu5dEo/8B9ryv5BqQZP+log+wyN0/dfevgcmE/V6jKorPwsMozgUm1fTnpqKC\nc0pWjj8lhWows1zgcOCtBLOPNrP3zWy6mfXIaGDgwMtmNtvMRiWY3wn4PG68mOwktmEk/0fM5v4r\ntZ9HzxCPXr+RYJnasC9HEq78EqnsWEi3q6MiroeSFH/Uhv13PLDS3RcmmZ+xfVjunJKV409JYQ+Z\nWQvgGeAn7r6x3Ox3CUUiecC9wJQMh3esu+cDpwI/MrMTys1P9JiujLZNNrO9gEHAUwlmZ3v/VUVW\n96WZjSU847wwySKVHQvpNB44AOgNLCcU0ZSX9WMRGE7FVwkZ2YeVnFOSrpZgWrX2n5LCHjCzJoQ/\nXqG7/7X8fHff6O5fRu+nAU3MrH2m4nP3ZdHrF8CzhEv0eMVAl7jxzsCyzEQXcyrwrruvLD8j2/sv\nzsrSYrXo9YsEy2RtX0aVit8HRnhUwFxeCsdC2rj7Snff4e47gQeTfHZWj0UzawycDTyRbJlM7MMk\n55SsHH9KClUUlT/+GVjg7ncmWaZjtBxm1oewn9dkKL59zKxl6XtCheSH5RabClwUtUI6CthQepma\nQUl/nWVz/5UzFShtzXEx8FyCZV4CBphZm6h4ZEA0La3MbCDwM2CQu29Jskwqx0I6Y4yvpzoryWe/\nAxxoZt2jq8dhhP2eKScBH7l7caKZmdiHFZxTsnP8patGvb4OwHGEy7O5wJxoOA24ArgiWuZqYB6h\nJcV/gGMyGN+3os99P4phbDQ9Pj4D7ie0+vgAKMjwPmxOOMm3ipuW1f1HSFDLge2EX18/ANoBM4CF\n0WvbaNkC4E9x644EFkXDpRmKbRGhLLn0GPxjtOz+wLSKjoUM7r/HouNrLuEE983yMUbjpxFa3HyS\nrhgTxRdN/0vpcRe3bEb3YQXnlKwcf+rmQkREYlR8JCIiMUoKIiISo6QgIiIxSgoiIhKjpCAiIjFK\nCiIRM9thZXtwrbEeO80sN76HTpHaqnG2AxCpRba6e+9sByGSTbpSEKlE1J/+b8zs7Wj4djS9m5nN\niDp8m2FmXaPp+1l4xsH70XBMtKlGZvZg1Gf+y2a2d7T8aDObH21ncpa+pgigpCASb+9yxUfnxc3b\n6O59gPuAu6Jp9xG6IO9F6JDunmj6PcA/PXTol0+4ExbgQOB+d+8BrAeGRNPHAIdH27kiXV9OJBW6\no1kkYmZfunuLBNOLgO+5+6dRx2Ur3L2dma0mdN2wPZq+3N3bm9kqoLO7b4vbRi6h3/sDo/GfAU3c\n/Vdm9iLwJaE32CkedQYokg26UhBJjSd5n2yZRLbFvd/Brjq90wl9UR0BzI567hTJCiUFkdScF/f6\n7+j9vwi9egKMAN6I3s8ArgQws0Zmtm+yjZpZDtDF3V8D/gdoDex2tSKSKfpFIrLL3lb24e0vuntp\ns9SmZvYW4YfU8GjaaOAhM7sBWAVcGk3/MTDBzH5AuCK4ktBDZyKNgMfNrBWh99rfu/v6GvtGIlWk\nOgWRSkR1CgXuvjrbsYikm4qPREQkRlcKIiISoysFERGJUVIQEZEYJQUREYlRUhARkRglBRERifn/\nyH6J0foFIvkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "epochs = range(1, len(loss_values)+1)\n",
    "\n",
    "plt.plot(epochs, acc_values, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc_values, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining the Model from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 124us/step - loss: 2.5402 - acc: 0.5222 - val_loss: 1.6738 - val_acc: 0.6530\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 111us/step - loss: 1.3713 - acc: 0.7127 - val_loss: 1.2764 - val_acc: 0.7180\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 1.0141 - acc: 0.7783 - val_loss: 1.1323 - val_acc: 0.7500\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.7982 - acc: 0.8251 - val_loss: 1.0539 - val_acc: 0.7600\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 116us/step - loss: 0.6395 - acc: 0.8627 - val_loss: 0.9752 - val_acc: 0.7940\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 114us/step - loss: 0.5122 - acc: 0.8925 - val_loss: 0.9107 - val_acc: 0.8120\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 120us/step - loss: 0.4119 - acc: 0.9143 - val_loss: 0.8932 - val_acc: 0.8210\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 114us/step - loss: 0.3355 - acc: 0.9287 - val_loss: 0.8729 - val_acc: 0.8260\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.2782 - acc: 0.9375 - val_loss: 0.9337 - val_acc: 0.8020\n",
      "2246/2246 [==============================] - 0s 121us/step\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=9,\n",
    "                   batch_size=512,\n",
    "                   validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: [1.0220439414944058, 0.7764915405695499]\n"
     ]
    }
   ],
   "source": [
    "print(\"Results:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives an accuracy of ~78%. Compare this to a random classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random accuracy: 0.182546749777382\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "test_labels_copy = copy.copy(test_labels)\n",
    "np.random.shuffle(test_labels_copy)\n",
    "hits_array = np.array(test_labels) == np.array(test_labels_copy)\n",
    "print(\"random accuracy:\", float(np.sum(hits_array))/len(test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Predictions on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: 2 (2246, 46) float32\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test)\n",
    "print(\"predictions:\", predictions.ndim, predictions.shape, predictions.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99999994\n"
     ]
    }
   ],
   "source": [
    "# verify that the probabilities in a prediction sum to 1\n",
    "print(np.sum(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0642886e-05 8.1068370e-05 2.5746222e-05 9.7177839e-01 1.7057892e-02\n",
      " 1.1642452e-07 8.8585773e-05 3.1081974e-05 3.2074451e-03 2.1114970e-06\n",
      " 3.0945062e-05 1.5532039e-03 5.0456270e-05 2.6648800e-05 4.3824434e-06\n",
      " 1.8163822e-05 9.3397498e-04 1.9112643e-04 2.8083156e-04 1.1390189e-03\n",
      " 7.5731735e-04 4.4485461e-04 7.0230226e-06 5.1655512e-05 1.2498930e-05\n",
      " 3.0360903e-04 2.5147256e-06 2.6472377e-05 8.1189501e-06 9.8914716e-05\n",
      " 3.4696018e-04 1.9335317e-04 1.1334881e-05 3.9051505e-05 3.7262886e-05\n",
      " 2.0709464e-05 1.5663520e-04 4.6035559e-05 9.4092902e-05 2.8505389e-04\n",
      " 3.3509088e-05 4.6048863e-04 1.8435343e-06 3.3028991e-05 6.4102082e-06\n",
      " 9.3290037e-06]\n"
     ]
    }
   ],
   "source": [
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Find the class with the highest probability\n",
    "print(np.argmax(predictions[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Diferent Way to Handle Labels and Loss\n",
    "An alternative way to encode the labels would be to convert them into an integer tensor:\n",
    "\n",
    "        y_train = np.array(train_labels)\n",
    "        y_test = np.array(test_labels)\n",
    "\n",
    "In this case, you would need to change your loss function to \"sparse_categorical_crossentropy\"\n",
    "\n",
    "        model.compile(optimizer='rmsprop',\n",
    "                      loss='sparse_categorical_crossentropy',\n",
    "                      metrics='['acc'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Try using 32-unit hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 101us/step - loss: 3.0420 - acc: 0.4959 - val_loss: 2.3143 - val_acc: 0.5780\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 84us/step - loss: 1.9050 - acc: 0.6254 - val_loss: 1.6516 - val_acc: 0.6490\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 82us/step - loss: 1.4018 - acc: 0.7013 - val_loss: 1.3732 - val_acc: 0.7000\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 81us/step - loss: 1.1370 - acc: 0.7534 - val_loss: 1.2102 - val_acc: 0.7290\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.9591 - acc: 0.7937 - val_loss: 1.1103 - val_acc: 0.7510\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 83us/step - loss: 0.8200 - acc: 0.8256 - val_loss: 1.0520 - val_acc: 0.7630\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 84us/step - loss: 0.7067 - acc: 0.8460 - val_loss: 0.9879 - val_acc: 0.7810\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 82us/step - loss: 0.6086 - acc: 0.8664 - val_loss: 0.9682 - val_acc: 0.7960\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 94us/step - loss: 0.5266 - acc: 0.8834 - val_loss: 0.9416 - val_acc: 0.7930\n",
      "2246/2246 [==============================] - 0s 91us/step\n",
      "Results: [0.995545125495931, 0.7751558326443496]\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=9,\n",
    "                   batch_size=512,\n",
    "                   validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "print(\"Results:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Try using 128 unit hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 180us/step - loss: 2.2403 - acc: 0.5251 - val_loss: 1.3922 - val_acc: 0.6810\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 154us/step - loss: 1.1567 - acc: 0.7489 - val_loss: 1.1159 - val_acc: 0.7630\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 155us/step - loss: 0.8098 - acc: 0.8266 - val_loss: 1.0090 - val_acc: 0.7790\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 155us/step - loss: 0.5934 - acc: 0.8773 - val_loss: 0.9372 - val_acc: 0.7950\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 156us/step - loss: 0.4287 - acc: 0.9112 - val_loss: 0.8927 - val_acc: 0.8150\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 155us/step - loss: 0.3246 - acc: 0.9330 - val_loss: 0.8799 - val_acc: 0.8240\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 158us/step - loss: 0.2539 - acc: 0.9445 - val_loss: 0.9215 - val_acc: 0.8080\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 159us/step - loss: 0.2126 - acc: 0.9486 - val_loss: 0.9038 - val_acc: 0.8220\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 164us/step - loss: 0.1819 - acc: 0.9520 - val_loss: 0.9594 - val_acc: 0.8150\n",
      "2246/2246 [==============================] - 0s 178us/step\n",
      "Results: [1.0488836682490335, 0.7853962600178095]\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(128, activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=9,\n",
    "                   batch_size=512,\n",
    "                   validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "print(\"Results:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Try using 1 hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 131us/step - loss: 2.5599 - acc: 0.5796 - val_loss: 1.7985 - val_acc: 0.6620\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 110us/step - loss: 1.4454 - acc: 0.7214 - val_loss: 1.3311 - val_acc: 0.7210\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 108us/step - loss: 1.0492 - acc: 0.7858 - val_loss: 1.1277 - val_acc: 0.7670\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 108us/step - loss: 0.8210 - acc: 0.8326 - val_loss: 1.0177 - val_acc: 0.7880\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 108us/step - loss: 0.6604 - acc: 0.8682 - val_loss: 0.9411 - val_acc: 0.8030\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.5399 - acc: 0.8914 - val_loss: 0.8971 - val_acc: 0.8100\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.4436 - acc: 0.9090 - val_loss: 0.8529 - val_acc: 0.8210\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.3700 - acc: 0.9246 - val_loss: 0.8365 - val_acc: 0.8220\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 117us/step - loss: 0.3113 - acc: 0.9322 - val_loss: 0.8107 - val_acc: 0.8320\n",
      "2246/2246 [==============================] - 0s 126us/step\n",
      "Results: [0.9103519436724995, 0.7943009795191451]\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu',input_shape=(10000,)))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "history = model.fit(partial_x_train,\n",
    "                   partial_y_train,\n",
    "                   epochs=9,\n",
    "                   batch_size=512,\n",
    "                   validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, one_hot_test_labels)\n",
    "print(\"Results:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Try using 3 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7982 samples, validate on 1000 samples\n",
      "Epoch 1/9\n",
      "7982/7982 [==============================] - 1s 144us/step - loss: 2.5310 - acc: 0.4595 - val_loss: 1.6654 - val_acc: 0.6060\n",
      "Epoch 2/9\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 1.4217 - acc: 0.6835 - val_loss: 1.3320 - val_acc: 0.7070\n",
      "Epoch 3/9\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 1.0833 - acc: 0.7616 - val_loss: 1.1771 - val_acc: 0.7480\n",
      "Epoch 4/9\n",
      "7982/7982 [==============================] - 1s 112us/step - loss: 0.8613 - acc: 0.8141 - val_loss: 1.0723 - val_acc: 0.7830\n",
      "Epoch 5/9\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.6939 - acc: 0.8438 - val_loss: 1.0052 - val_acc: 0.7890\n",
      "Epoch 6/9\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.5612 - acc: 0.8732 - val_loss: 0.9920 - val_acc: 0.7930\n",
      "Epoch 7/9\n",
      "7982/7982 [==============================] - 1s 113us/step - loss: 0.4548 - acc: 0.9009 - val_loss: 0.9936 - val_acc: 0.7870\n",
      "Epoch 8/9\n",
      "7982/7982 [==============================] - 1s 114us/step - loss: 0.3600 - acc: 0.9207 - val_loss: 0.9979 - val_acc: 0.7910\n",
      "Epoch 9/9\n",
      "7982/7982 [==============================] - 1s 115us/step - loss: 0.3018 - acc: 0.9327 - val_loss: 0.9948 - val_acc: 0.8020\n",
      "2246/2246 [==============================] - 0s 117us/step\n",
      "Results: [1.1136978487828324, 0.7733748887440824]\n"
     ]
    }
   ],
   "source": [
    "model4 = models.Sequential()\n",
    "model4.add(layers.Dense(64, activation='relu',input_shape=(10000,)))\n",
    "model4.add(layers.Dense(64, activation='relu'))\n",
    "model4.add(layers.Dense(64, activation='relu'))\n",
    "model4.add(layers.Dense(46, activation='softmax'))\n",
    "model4.compile(optimizer='rmsprop',\n",
    "               loss='categorical_crossentropy',\n",
    "               metrics=['accuracy'])\n",
    "history4 = model4.fit(partial_x_train,\n",
    "                     partial_y_train,\n",
    "                     epochs=9,\n",
    "                     batch_size=512,\n",
    "                     validation_data=(x_val, y_val))\n",
    "results4 = model4.evaluate(x_test, one_hot_test_labels)\n",
    "print(\"Results:\", results4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras36",
   "language": "python",
   "name": "keras36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
